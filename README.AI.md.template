# README.AI.md: Knowledge Base for Subagents

This document serves as the comprehensive knowledge base for AI subagents working on the CUDA implementation of the Eulerian Video Magnification algorithm. It contains the most up-to-date information about technical details, implementation choices, current status, and issues to be aware of when implementing new kernels.

## Algorithm Overview

Eulerian Video Magnification is a technique that amplifies subtle variations in video, making invisible changes visible. The process involves:

1. **Spatial Decomposition**: Breaking down each frame into multiple spatial frequency bands using Gaussian and Laplacian pyramids
2. **Temporal Filtering**: Applying a bandpass filter to isolate temporal variations of interest
3. **Signal Amplification**: Enhancing the filtered signal by a specified factor
4. **Reconstruction**: Combining the amplified signal with the original video

### Key Algorithmic Insights for Subagents

- Color conversion (RGB ↔ YIQ) is used to separate intensity from chrominance, allowing for independent amplification
- The Gaussian pyramid provides multi-scale representation through progressive blurring and downsampling
- The Laplacian pyramid is derived from the Gaussian pyramid and enables band-pass filtering in the spatial domain
- Temporal filtering isolates frequency bands of interest in the time domain
- Signal amplification is performed on specific components (typically Y for motion, I/Q for color)

## Implementation Status

**ATTENTION SUBAGENTS**: This section will be continuously updated as the implementation progresses. Check this section first to understand what has been completed and what needs to be worked on next.

| Component | Status | Validation | Notes for Subagents |
|-----------|--------|------------|---------------------|
| Project Setup | Complete | N/A | Directory structure created |
| Color Conversion | Not Started | Not Started | Next component to implement. Focus on RGB ↔ YIQ conversion |
| Gaussian Pyramid | Not Started | Not Started | Requires correct implementation of 2D separable kernels |
| Laplacian Pyramid | Not Started | Not Started | Depends on Gaussian pyramid implementation |
| Butterworth Filter | Not Started | Not Started | Critical for accurate temporal filtering |
| Temporal Filtering | Not Started | Not Started | Complex data dependency across frames |
| Signal Processing | Not Started | Not Started | Requires careful handling of amplification factors |
| End-to-End Pipeline | Not Started | Not Started | Final integration step |

### Critical Dependencies Between Components
- Color conversion must be implemented first as it's used by all subsequent steps
- Gaussian pyramid must be correctly implemented before Laplacian pyramid
- Temporal filtering requires accurate Butterworth filter implementation
- Full pipeline integration depends on all previous components

## CUDA Implementation Guidance for Subagents

### Memory Management Strategy

When implementing your assigned kernel, follow these memory management principles:
- Keep all computation on the GPU; avoid host-device transfers within your kernel
- Use appropriate memory types for different data patterns:
  - Global memory: For primary frame data and when coalesced access is possible
  - Shared memory: For neighborhood operations with multiple accesses to same data
  - Constant memory: For small, read-only data like filter coefficients
- Be explicit about boundary handling (clamping, mirroring, etc.)
- Check for out-of-bounds accesses in your kernel code
- Implement proper error checking after every CUDA API call

### Kernel Design Guidelines for Subagents

When implementing your kernel:
- Each thread should process one output element (e.g., one pixel)
- Use 2D thread blocks for image processing (typically 16x16 or 32x8)
- Implement proper boundary checking for all array accesses
- For filters and neighborhood operations, use shared memory with appropriate padding
- Remember that most operations in image processing are inherently parallel
- Be mindful of thread divergence due to conditional statements
- Align memory accesses to enable coalescing where possible

### Thread Organization Examples
For 2D image processing:
```cuda
// Thread block size
dim3 blockSize(16, 16);
// Grid size
dim3 gridSize((width + blockSize.x - 1) / blockSize.x, 
              (height + blockSize.y - 1) / blockSize.y);
// Kernel launch
myKernel<<<gridSize, blockSize>>>(d_input, d_output, width, height);
```

### Validation Methodology for Subagents

When validating your kernel implementation:

1. **Test Data Source**: Use fixed inputs from `cpp/tests/data/` directory
2. **Comparison Method**: 
   - For exact data types (int, uint8): Compare for exact matches
   - For floating-point: Use epsilon comparison (typically 1e-5 or 1e-6 for float)
3. **Error Metrics to Calculate and Report**:
   - Maximum absolute error: `max(|CPU - GPU|)`
   - Mean absolute error: `mean(|CPU - GPU|)`
   - PSNR (Peak Signal-to-Noise Ratio)
4. **Validation Process**:
   - Run CPU implementation with fixed input
   - Run your CUDA kernel with identical input
   - Compare outputs element-by-element
   - Calculate and report error metrics
   - If errors exceed thresholds, debug and iterate

5. **Common Validation Issues to Check**:
   - Boundary handling differences
   - Floating-point precision differences
   - Thread block edge effects
   - Off-by-one errors in indexing
   - Uninitialized memory

## Technical Details for Subagent Implementation

### Color Conversion Implementation Notes

**RGB to YIQ Conversion**:
- Formula: 
  ```
  Y = 0.299 * R + 0.587 * G + 0.114 * B
  I = 0.596 * R - 0.274 * G - 0.322 * B
  Q = 0.211 * R - 0.523 * G + 0.312 * B
  ```
- Implementation approach: Each thread processes one pixel, computing all three channels
- Memory layout: Use AoS (RGB interleaved) or SoA (planar) based on input format
- Validation data: Use appropriate test files from `cpp/tests/data/` directory

**YIQ to RGB Conversion**:
- Formula:
  ```
  R = Y + 0.956 * I + 0.621 * Q
  G = Y - 0.272 * I - 0.647 * Q
  B = Y - 1.105 * I + 1.702 * Q
  ```
- Implementation approach: Same as RGB to YIQ but inverse transform
- Potential precision issues: Be aware of potential floating-point precision differences
- Validation data: Test roundtrip conversion for consistency

### Gaussian Pyramid Implementation Notes

**Downsampling (pyrDown)**:
- Algorithm: (1) Apply Gaussian blur with kernel [1,4,6,4,1]/16, (2) Downsample by factor of 2
- Kernel strategy: Consider separable 1D convolutions for better performance
- Memory considerations: Account for reduced output size (width/2, height/2)
- Thread organization: Process output pixels directly, calculating input coordinates
- Memory access pattern: Use shared memory for filter neighborhood

**Upsampling (pyrUp)**:
- Algorithm: (1) Upsample by factor of 2 with zeros, (2) Apply scaled Gaussian blur
- Kernel strategy: Consider separable 1D convolutions
- Memory considerations: Account for increased output size (width*2, height*2)
- Thread organization: Process output pixels directly
- Common pitfalls: Watch for edge handling and proper scaling

### Laplacian Pyramid Implementation Notes

**Construction**:
- Algorithm: Laplacian_level(i) = Gaussian_level(i) - pyrUp(Gaussian_level(i+1))
- Dependency: Requires correct Gaussian pyramid implementation
- Memory management: Consider implementing as composite of Gaussian operations
- Validation approach: Compare each level individually with CPU implementation

**Reconstruction**:
- Algorithm: Start from lowest level, then iteratively: Result = pyrUp(Result) + Laplacian_level
- Implementation strategy: Process from smallest to largest resolution
- Memory management: Consider in-place operations where possible
- Common pitfalls: Watch for proper accumulation and level-by-level validation

### Butterworth Filter Implementation Notes

**Filter Design**:
- Formula for bandpass filter: H(ω) = 1 / (1 + (ω/ω_l)^(-2n)) * 1 / (1 + (ω/ω_h)^(2n))
  where ω_l is lower cutoff, ω_h is higher cutoff, and n is filter order
- Memory approach: Store filter coefficients in constant memory
- Computation strategy: Direct implementation of difference equations
- Validation: Compare frequency response with CPU implementation

### Temporal Filtering Implementation Notes

**Implementation Strategy**:
- Algorithm: Apply Butterworth filter coefficients to time series of each pixel
- Memory organization: Process in temporal chunks to maintain locality
- Thread arrangement: Each thread processes one spatial location across multiple frames
- Cache utilization: Optimize for temporal locality in memory access
- Common challenges: Handling first/last frames with insufficient history

### Signal Processing Implementation Notes

**Amplification**:
- Algorithm: Scale filtered signal by amplification factor
- Implementation considerations: Handle amplification differently for Y, I, Q channels
- Precision requirements: Maintain sufficient precision during multiplication
- Common pitfalls: Watch for overflow/underflow in fixed-point representations

**Reconstruction**:
- Algorithm: Add amplified signal back to original
- Implementation strategy: Simple element-wise addition
- Validation approach: Compare with CPU output for identical inputs
- Potential issues: Accumulated errors from earlier stages

## Performance Analysis for Subagents

**IMPORTANT**: As a subagent implementing a kernel, you must measure and report these metrics for your implementation:

| Metric | How to Measure | Importance |
|--------|----------------|------------|
| Kernel Execution Time | Use cudaEventRecord/Synchronize | Primary performance indicator |
| Memory Bandwidth | Calculate based on data size and time | Detect memory bottlenecks |
| Compute Utilization | Use Nsight Compute (if available) | Identify compute efficiency |
| Thread Block Efficiency | Analyze occupancy | Optimize grid/block dimensions |

### Performance Optimization Guidance for Subagents
- Start with a correct implementation before optimizing
- Focus first on memory access patterns
- Consider kernel fusion to reduce memory transfers
- Use shared memory for data reuse
- Balance register usage against occupancy

### Current Performance Measurements
| Operation | CPU Time (ms) | GPU Time (ms) | Speedup | Notes for Subagents |
|-----------|---------------|---------------|---------|---------------------|
| Color Conversion | TBD | TBD | TBD | First kernel to implement and benchmark |
| Gaussian Pyramid | TBD | TBD | TBD | Performance sensitive to thread block size |
| Laplacian Pyramid | TBD | TBD | TBD | Depends on Gaussian pyramid performance |
| Temporal Filtering | TBD | TBD | TBD | Memory access pattern critical |
| Signal Processing | TBD | TBD | TBD | Usually compute-bound |
| End-to-End Pipeline | TBD | TBD | TBD | Overall performance metric |

## Critical Issues and Debugging Information for Subagents

### Known Issues in Current Implementation
**ATTENTION SUBAGENTS**: This section contains critical known issues that you should be aware of when implementing your kernel. Check this section frequently as it will be updated as implementation progresses.

- [This section will be populated as issues are discovered]

### Common CUDA Implementation Pitfalls
As a subagent, be aware of these common issues:

1. **Race Conditions**: When multiple threads write to the same memory location
   - Solution: Use atomic operations or ensure thread independence

2. **Bank Conflicts in Shared Memory**: Reduced shared memory throughput
   - Solution: Adjust shared memory access patterns or padding

3. **Warp Divergence**: Threads in a warp taking different execution paths
   - Solution: Minimize conditional code or ensure conditions align with warp boundaries

4. **Uncoalesced Memory Access**: Inefficient global memory access
   - Solution: Ensure consecutive threads access consecutive memory addresses

5. **Insufficient Error Checking**: Missing CUDA error detection
   - Solution: Add error checking after ALL CUDA API calls

6. **Boundary Handling Issues**: Incorrect handling of image edges
   - Solution: Implement proper boundary checking or padding

7. **Numerical Precision**: Floating-point operations may yield different results on CPU vs GPU
   - Solution: Use appropriate epsilon values for comparisons

### Debugging Tools and Techniques for Subagents
- Use `printf` debugging in kernels for simple cases
- Check for correct thread/block indices calculation
- Validate intermediate results against CPU implementation
- Isolate components for easier debugging
- Use reduced input sizes during initial implementation

## Important References for Subagents

### Original CPU Implementation Key Files
- `cpp/include/color_conversion.hpp` and `cpp/src/color_conversion.cpp`: RGB ↔ YIQ conversion
- `cpp/include/gaussian_pyramid.hpp` and `cpp/src/gaussian_pyramid.cpp`: Gaussian pyramid implementation
- `cpp/include/laplacian_pyramid.hpp` and `cpp/src/laplacian_pyramid.cpp`: Laplacian pyramid implementation
- `cpp/include/butterworth.hpp` and `cpp/src/butterworth.cpp`: Butterworth filter implementation
- `cpp/include/temporal_filter.hpp` and `cpp/src/temporal_filter.cpp`: Temporal filtering
- `cpp/include/processing.hpp` and `cpp/src/processing.cpp`: Signal processing operations

### Critical Test Files
- `cpp/tests/test_cpu_color.cpp`: Tests for color conversion
- `cpp/tests/test_gaussian.cpp`: Tests for Gaussian pyramid
- `cpp/tests/test_laplacian.cpp`: Tests for Laplacian pyramid
- `cpp/tests/test_butterworth.cpp`: Tests for Butterworth filter
- `cpp/tests/test_cpu_temporal.cpp`: Tests for temporal filtering
- `cpp/tests/test_processing.cpp`: Tests for signal processing

### CUDA Resources
- CUDA Programming Guide: https://docs.nvidia.com/cuda/cuda-c-programming-guide/
- CUDA Best Practices Guide: https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/

### Original Paper
Wu, H. Y., Rubinstein, M., Shih, E., Guttag, J., Durand, F., & Freeman, W. (2012). Eulerian video magnification for revealing subtle changes in the world. ACM Transactions on Graphics (TOG), 31(4), 1-8.